[Espa√±ol](README-es.md) | [English](README.md)

# BeatFinder üéß: Clasificaci√≥n de G√©neros Musicales con Redes Neuronales

**BeatFinder** es el proyecto final del Bootcamp de Data Science & Machine Learning en 4Geeks Academy. Su objetivo principal es clasificar autom√°ticamente grabaciones de audio en uno de sus 16 g√©neros principales utilizando las caracter√≠sticas ac√∫sticas de la se√±al y un modelo de Red Neuronal Profunda (DNN).

## üìÑ √çndice

- [¬øC√≥mo Usarlo?](#-c√≥mo-usarlo) üöÄ
- [Objetivo del Proyecto](#-objetivo-del-proyecto) üéØ
- [Tecnolog√≠a y Herramientas](#-tecnolog√≠a-y-herramientas) üß†
- [Exploraci√≥n y Preprocesamiento de Datos (EDA)](#-exploraci√≥n-y-preprocesamiento-de-datos-eda) üìä
- [Resultados del Modelo](#-resultados-del-modelo) üèÜ
- [Estructura del Repositorio](#-estructura-del-repositorio) ‚öôÔ∏è
- [Pr√≥ximas Ideas y Expansi√≥n del Proyecto](#-pr√≥ximas-ideas-y-expansi√≥n-del-proyecto) üöÄ
- [Co-creadores](#-co-creadores) üßë‚Äçüíª

---

## üöÄ ¬øC√≥mo Usarlo?

![preview de la webapp de Beatfinder](image-1.png)

La aplicaci√≥n BeatFinder est√° desplegada usando Streamlit. Para ejecutarla localmente y utilizar el modelo de clasificaci√≥n, sigue estos pasos:

1.  **Navega al Directorio Fuente:**
    Abre tu terminal o s√≠mbolo del sistema y cambia el directorio a la carpeta `src`, donde se encuentra el archivo principal de la aplicaci√≥n (`app.py`).

    ```bash
    cd src
    ```

2.  **Ejecuta la Aplicaci√≥n Streamlit:**
    Ejecuta la aplicaci√≥n utilizando la interfaz de l√≠nea de comandos de Streamlit.

    ```bash
    python -m streamlit run app.py
    ```

3.  **Accede a la Aplicaci√≥n:**
    Se abrir√° autom√°ticamente una nueva pesta√±a en tu navegador web, dirigi√©ndote a la aplicaci√≥n en ejecuci√≥n o haz `Ctrl+click` para abrirla (normalmente en `http://localhost:8501`).

4.  **Carga y Clasifica:**
    Dentro de la aplicaci√≥n, sube un archivo de audio y haz clic en el bot√≥n **"Predict"** para iniciar la clasificaci√≥n del g√©nero.


## üéØ Objetivo del Proyecto

El objetivo principal de este proyecto es desarrollar un modelo de clasificaci√≥n capaz de identificar el g√©nero musical de una pista bas√°ndose √∫nicamente en sus propiedades ac√∫sticas.

La capacidad de realizar esta tarea de forma autom√°tica resulta valiosa en
contextos como:

1. La **optimizaci√≥n** de sistemas de recomendaci√≥n musical,
2. La **organizaci√≥n** eficiente de grandes bibliotecas digitales,
3. El **an√°lisis** de tendencias en la industria musical.

Para esto hemos realizado lo siguiente:

- **Extracci√≥n de Caracter√≠sticas (Feature Extraction)**: Utilizando Librosa, transformamos las se√±ales de audio (representadas por el dataset [FMA](https://www.kaggle.com/datasets/imsparsh/fma-free-music-archive-small-medium) en caracter√≠sticas num√©ricas clave (MFCCs, Centroide Espectral, Tonalidad, etc.).

- **Preprocesamiento y Exploraci√≥n (EDA)**: Limpiamos, analizamos y estandarizamos los datos, comparando el impacto de la detecci√≥n y acotamiento de outliers.

- **Modelado**: Dise√±amos y optimizamos una Red Neuronal Densa (DNN) para maximizar la precisi√≥n en la identificaci√≥n de g√©neros tras explorar otros modelos as√≠ como Random Forest, SVM o Regresi√≥n Log√≠sitca.

_Finalmente el modelo tiene 49,133 filas y 519 variables pudiendo predecir hasta 16 g√©neros distintos._

## üß† Tecnolog√≠a y Herramientas

| Categor√≠a             | Herramientas Clave                                                                                                                 |
| :-------------------- | :--------------------------------------------------------------------------------------------------------------------------------- |
| **Modelado & ML**     | **TensorFlow/Keras** (Redes Neuronales), **Scikit-learn** (Random Forest, SVM), **Keras Tuner** (Optimizaci√≥n de Hiperpar√°metros). |
| **An√°lisis de Audio** | **Librosa** (Extracci√≥n de MFCCs, ZCR, Tonnetz, etc.)                                                                              |
| **Lenguaje**          | **Python, Streamlit**                                                                                                              |
| **Gesti√≥n de Datos**  | **Pandas, NumPy**                                                                                                                  |
| **Visualizaci√≥n**     | **Seaborn, Matplotlib**                                                                                                            |
| **Ingenier√≠a de ML**  | Guardado de **scalers** (`.pkl`) y **modelos**.                                                                                    |

## üìä Exploraci√≥n y Preprocesamiento de Datos (EDA)

El proyecto se bas√≥ en el dataset FMA (Free Music Archive), que contiene metadatos y caracter√≠sticas pre-extra√≠das.

Desaf√≠os Superados:

- **Limpieza de Columnas**: Se manej√≥ la compleja jerarqu√≠a de tres niveles en las columnas de caracter√≠sticas y se convirti√≥ la informaci√≥n de g√©nero de strings a listas.

- **Selecci√≥n del Dataset Ganador**: Se evaluaron 6 combinaciones de datos (Con/Sin Outliers, Crudos/Normalizados/MinMax) para determinar cu√°l ofrec√≠a la mejor Accuracy inicial, encontrando que [Menciona el dataset ganador aqu√≠, ej: X_train_sin_outliers_norm] fue el m√°s efectivo para la clasificaci√≥n.

- **Gesti√≥n del Desequilibrio**: El an√°lisis univariante revel√≥ un marcado desequilibrio de clases (predominio de Electronic, Rock, Experimental), un factor cr√≠tico a considerar en la evaluaci√≥n del rendimiento. Por ello y por falta de datos decidimos mantener los g√©neros musicales m√°s representativos.

- **Gesti√≥n de la RAM**: Para realizar nuestro trabajo nos hemos valido de Google Colab y GitHub Codespaces y pronto nos quedamos sin RAM debido a la gran cantidad de datos que el ordenador deb√≠a procesar. Para ello ajustamos los datatypes y eliminamos todas aquellas variables que dejamos de usar.

## üèÜ Resultados del Modelo

Se compararon cuatro modelos principales. El mejor rendimiento se logr√≥ tras la optimizaci√≥n de hiperpar√°metros de la Red Neuronal mediante Keras Tuner utilizando el mejor dataset seleccionado.

| Modelo                 | Optimizaci√≥n                | Accuracy |
| :--------------------- | :-------------------------- | :------- |
| **Red Neuronal (DNN)** | Keras Tuner                 | 69%      |
| Random Forest          | RandomizedSearchCV          | 55'34%   |
| SVM (RBF/Lineal)       | RandomizedSearchCV (Subset) | 62'65%   |
| Regresi√≥n Log√≠stica    | Base                        | 56'56%   |

ü•á El modelo ganador fue la Red Neuronal con una precisi√≥n final superior al 69%.

## ‚öôÔ∏è Estructura del Repositorio

```
‚îú‚îÄ‚îÄ music_genre_identifier/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processed/ (Contiene .parquet de X_train/test normalizados/minmaxed)
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ factorized_data/ (Contiene factorized_genre_top.json para decodificaci√≥n)
‚îÇ       ‚îî‚îÄ‚îÄ models/ (Contiene el scaler y los modelos .pkl para despliegue en Streamlit)
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ neural_network.pkl (El objeto del modelo ganador final)
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Pr√≥ximas Ideas y Expansi√≥n del Proyecto

### 1. Ideas de Producto y UX/UI (Lado Izquierdo)

Estas ideas se centran en c√≥mo el usuario final interactuar√≠a con el producto y c√≥mo se generar√≠a valor.

- **Ingresar una estrofa y obtener autom√°ticamente informaci√≥n detallada de la canci√≥n**: Esto implica un motor de b√∫squeda de audio avanzado (similar a Shazam o SoundHound), que requerir√≠a un modelo de Machine Learning para la b√∫squeda por hashing de audio.

- **Integrar un sistema de recomendaci√≥n**: Utilizar el modelo de clasificaci√≥n de g√©neros y las caracter√≠sticas extra√≠das para recomendar canciones similares, lo que requiere un modelo de recomendaci√≥n adicional (basado en contenido o filtrado colaborativo).

- **Visualizaci√≥n del audio y la playlist recomendada**: Podr√≠as escuchar una preview de la canci√≥n seleccionada tanto la que subes como las de la playlist.

- **Monetizar**: Un banner con publicidad o incluso una suscripci√≥n de pago para evitar estos anuncios.

### 2. Ideas de Desarrollo T√©cnico y ML (Lado Derecho)

Estas ideas son mejoras directas para la base de datos y el modelo de Machine Learning.

- **Explorar t√©cnicas avanzadas de manejo de desbalance de clases**: Esto mejorar√≠a la precisi√≥n del modelo as√≠ como poder identificar m√°s g√©neros de m√∫sica que ahora mismo no est√°n disponibles.

- **Realizar ingenier√≠a de caracter√≠sticas m√°s profunda o selecci√≥n de caracter√≠sticas m√°s sofisticada**: as√≠ como BPM, segmentaci√≥n, etc.

- **Integraci√≥n con APIs externas (Spotify, Apple Music, YouTube Music)**: Es la implementaci√≥n pr√°ctica de la preview de la canci√≥n que mencionamos anteriormente.

Aqu√≠ un mockup de c√≥mo podr√≠a verse la aplicaci√≥n web:

<img width="631" height="367" alt="image" src="https://github.com/user-attachments/assets/6cc471df-e92e-46cc-9a72-533a6adde78f" />

## üßë‚Äçüíª Co-creadores

Este proyecto fue desarrollado en colaboraci√≥n por:

[Daniel P√°ez](https://github.com/danielpaez-dev) | [Ivan D√≠az](https://github.com/ivandla96) | [Tulio Gim√©nez](https://github.com/TulioGimenez)
