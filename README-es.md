[EspaÃ±ol](README-es.md) | [English](README.md)

# BeatFinder ğŸ§: ClasificaciÃ³n de GÃ©neros Musicales con Redes Neuronales
**BeatFinder** es el proyecto final del Bootcamp de Data Science & Machine Learning en 4Geeks Academy. Su objetivo principal es clasificar automÃ¡ticamente grabaciones de audio en uno de sus 16 gÃ©neros principales utilizando las caracterÃ­sticas acÃºsticas de la seÃ±al y un modelo de Red Neuronal Profunda (DNN).

## ğŸ“„ Ãndice
- [Objetivo del Proyecto](#-objetivo-del-proyecto) ğŸ¯
- [TecnologÃ­a y Herramientas](#-tecnologÃ­a-y-herramientas) ğŸ§ 
- [ExploraciÃ³n y Preprocesamiento de Datos (EDA)](#-exploraciÃ³n-y-preprocesamiento-de-datos-eda) ğŸ“Š
- [Resultados del Modelo](#-resultados-del-modelo) ğŸ†
- [Estructura del Repositorio](#-estructura-del-repositorio) âš™ï¸
- [PrÃ³ximas Ideas y ExpansiÃ³n del Proyecto](#-prÃ³ximas-ideas-y-expansiÃ³n-del-proyecto) ğŸš€
- [Co-creadores](#-co-creadores) ğŸ§‘â€ğŸ’»

---

## ğŸ¯ Objetivo del Proyecto
El objetivo principal de este proyecto es desarrollar un modelo de clasificaciÃ³n capaz de identificar el gÃ©nero musical de una pista basÃ¡ndose Ãºnicamente en sus propiedades acÃºsticas.

La capacidad de realizar esta tarea de forma automÃ¡tica resulta valiosa en 
contextos como:
1. La **optimizaciÃ³n** de sistemas de recomendaciÃ³n musical,
2. La **organizaciÃ³n** eficiente de grandes bibliotecas digitales, 
3. El **anÃ¡lisis** de tendencias en la industria musical.


Para esto hemos realizado lo siguiente:
- **ExtracciÃ³n de CaracterÃ­sticas (Feature Extraction)**: Utilizando Librosa, transformamos las seÃ±ales de audio (representadas por el dataset [FMA](https://www.kaggle.com/datasets/imsparsh/fma-free-music-archive-small-medium) en caracterÃ­sticas numÃ©ricas clave (MFCCs, Centroide Espectral, Tonalidad, etc.).

- **Preprocesamiento y ExploraciÃ³n (EDA)**: Limpiamos, analizamos y estandarizamos los datos, comparando el impacto de la detecciÃ³n y acotamiento de outliers.

- **Modelado**: DiseÃ±amos y optimizamos una Red Neuronal Densa (DNN) para maximizar la precisiÃ³n en la identificaciÃ³n de gÃ©neros tras explorar otros modelos asÃ­ como Random Forest, SVM o RegresiÃ³n LogÃ­sitca.

*Finalmente el modelo tiene 49,133 filas y 519 variables pudiendo predecir hasta 16 gÃ©neros distintos.*

## ğŸ§  TecnologÃ­a y Herramientas
| CategorÃ­a | Herramientas Clave |
| :--- | :--- |
| **Modelado & ML** | **TensorFlow/Keras** (Redes Neuronales), **Scikit-learn** (Random Forest, SVM), **Keras Tuner** (OptimizaciÃ³n de HiperparÃ¡metros). |
| **AnÃ¡lisis de Audio** | **Librosa** (ExtracciÃ³n de MFCCs, ZCR, Tonnetz, etc.) |
| **Lenguaje** | **Python, Streamlit** |
| **GestiÃ³n de Datos** | **Pandas, NumPy** |
| **VisualizaciÃ³n** | **Seaborn, Matplotlib** |
| **IngenierÃ­a de ML** | Guardado de **scalers** (`.pkl`) y **modelos**. |

## ğŸ“Š ExploraciÃ³n y Preprocesamiento de Datos (EDA)
El proyecto se basÃ³ en el dataset FMA (Free Music Archive), que contiene metadatos y caracterÃ­sticas pre-extraÃ­das.

DesafÃ­os Superados:

- **Limpieza de Columnas**: Se manejÃ³ la compleja jerarquÃ­a de tres niveles en las columnas de caracterÃ­sticas y se convirtiÃ³ la informaciÃ³n de gÃ©nero de strings a listas.

- **SelecciÃ³n del Dataset Ganador**: Se evaluaron 6 combinaciones de datos (Con/Sin Outliers, Crudos/Normalizados/MinMax) para determinar cuÃ¡l ofrecÃ­a la mejor Accuracy inicial, encontrando que [Menciona el dataset ganador aquÃ­, ej: X_train_sin_outliers_norm] fue el mÃ¡s efectivo para la clasificaciÃ³n.

- **GestiÃ³n del Desequilibrio**: El anÃ¡lisis univariante revelÃ³ un marcado desequilibrio de clases (predominio de Electronic, Rock, Experimental), un factor crÃ­tico a considerar en la evaluaciÃ³n del rendimiento. Por ello y por falta de datos decidimos mantener los gÃ©neros musicales mÃ¡s representativos.

- **GestiÃ³n de la RAM**: Para realizar nuestro trabajo nos hemos valido de Google Colab y GitHub Codespaces y pronto nos quedamos sin RAM debido a la gran cantidad de datos que el ordenador debÃ­a procesar. Para ello ajustamos los datatypes y eliminamos todas aquellas variables que dejamos de usar.

## ğŸ† Resultados del Modelo
Se compararon cuatro modelos principales. El mejor rendimiento se logrÃ³ tras la optimizaciÃ³n de hiperparÃ¡metros de la Red Neuronal mediante Keras Tuner utilizando el mejor dataset seleccionado.

| Modelo | OptimizaciÃ³n | Accuracy |
| :--- | :--- | :--- |
| **Red Neuronal (DNN)** | Keras Tuner | 69% |
| Random Forest | RandomizedSearchCV | 55'34% |
| SVM (RBF/Lineal) | RandomizedSearchCV (Subset) | 62'65% |
| RegresiÃ³n LogÃ­stica | Base | 56'56% |


ğŸ¥‡ El modelo ganador fue la Red Neuronal con una precisiÃ³n final superior al 69%.

## âš™ï¸ Estructura del Repositorio
```
â”œâ”€â”€ music_genre_identifier/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ processed/ (Contiene .parquet de X_train/test normalizados/minmaxed)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ factorized_data/ (Contiene factorized_genre_top.json para decodificaciÃ³n)
â”‚       â””â”€â”€ models/ (Contiene el scaler y los modelos .pkl para despliegue en Streamlit)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ neural_network.pkl (El objeto del modelo ganador final)
â””â”€â”€ README.md
```

## ğŸš€ PrÃ³ximas Ideas y ExpansiÃ³n del Proyecto

### 1. Ideas de Producto y UX/UI (Lado Izquierdo)
Estas ideas se centran en cÃ³mo el usuario final interactuarÃ­a con el producto y cÃ³mo se generarÃ­a valor.

- **Ingresar una estrofa y obtener automÃ¡ticamente informaciÃ³n detallada de la canciÃ³n**: Esto implica un motor de bÃºsqueda de audio avanzado (similar a Shazam o SoundHound), que requerirÃ­a un modelo de Machine Learning para la bÃºsqueda por hashing de audio.

- **Integrar un sistema de recomendaciÃ³n**: Utilizar el modelo de clasificaciÃ³n de gÃ©neros y las caracterÃ­sticas extraÃ­das para recomendar canciones similares, lo que requiere un modelo de recomendaciÃ³n adicional (basado en contenido o filtrado colaborativo).

- **VisualizaciÃ³n del audio y la playlist recomendada**: PodrÃ­as escuchar una preview de la canciÃ³n seleccionada tanto la que subes como las de la playlist.

- **Monetizar**: Un banner con publicidad o incluso una suscripciÃ³n de pago para evitar estos anuncios.

### 2. Ideas de Desarrollo TÃ©cnico y ML (Lado Derecho)
Estas ideas son mejoras directas para la base de datos y el modelo de Machine Learning.

- **Explorar tÃ©cnicas avanzadas de manejo de desbalance de clases**: Esto mejorarÃ­a la precisiÃ³n del modelo asÃ­ como poder identificar mÃ¡s gÃ©neros de mÃºsica que ahora mismo no estÃ¡n disponibles.

- **Realizar ingenierÃ­a de caracterÃ­sticas mÃ¡s profunda o selecciÃ³n de caracterÃ­sticas mÃ¡s sofisticada**: asÃ­ como BPM, segmentaciÃ³n, etc.

- **IntegraciÃ³n con APIs externas (Spotify, Apple Music, YouTube Music)**: Es la implementaciÃ³n prÃ¡ctica de la preview de la canciÃ³n que mencionamos anteriormente.

AquÃ­ un mockup de cÃ³mo podrÃ­a verse la aplicaciÃ³n web:

<img width="631" height="367" alt="image" src="https://github.com/user-attachments/assets/6cc471df-e92e-46cc-9a72-533a6adde78f" />


## ğŸ§‘â€ğŸ’» Co-creadores
Este proyecto fue desarrollado en colaboraciÃ³n por:

[Daniel PÃ¡ez](https://github.com/danielpaez-dev) | [Ivan DÃ­az](https://github.com/ivandla96) | [Tulio GimÃ©nez](https://github.com/TulioGimenez)
