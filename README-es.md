[Espa√±ol](README-es.md) | [English](README.md)

# BeatFinder üéß: Clasificaci√≥n de G√©neros Musicales con Redes Neuronales
**BeatFinder** es el proyecto final del Bootcamp de Data Science & Machine Learning en 4Geeks Academy. Su objetivo principal es clasificar autom√°ticamente grabaciones de audio en uno de sus 16 g√©neros principales utilizando las caracter√≠sticas ac√∫sticas de la se√±al y un modelo de Red Neuronal Profunda (DNN).

## üéØ Objetivo del Proyecto
El objetivo principal de este proyecto es desarrollar un modelo de clasificaci√≥n capaz de identificar el g√©nero musical de una pista bas√°ndose √∫nicamente en sus propiedades ac√∫sticas.

La capacidad de realizar esta tarea de forma autom√°tica resulta valiosa en 
contextos como:
1. La **optimizaci√≥n** de sistemas de recomendaci√≥n musical,
2. La **organizaci√≥n** eficiente de grandes bibliotecas digitales, 
3. El **an√°lisis** de tendencias en la industria musical.


Para esto hemos realizado lo siguiente:
- **Extracci√≥n de Caracter√≠sticas (Feature Extraction)**: Utilizando Librosa, transformamos las se√±ales de audio (representadas por el dataset [FMA](https://www.kaggle.com/datasets/imsparsh/fma-free-music-archive-small-medium) en caracter√≠sticas num√©ricas clave (MFCCs, Centroide Espectral, Tonalidad, etc.).

- **Preprocesamiento y Exploraci√≥n (EDA)**: Limpiamos, analizamos y estandarizamos los datos, comparando el impacto de la detecci√≥n y acotamiento de outliers.

- **Modelado**: Dise√±amos y optimizamos una Red Neuronal Densa (DNN) para maximizar la precisi√≥n en la identificaci√≥n de g√©neros tras explorar otros modelos as√≠ como Random Forest, SVM o Regresi√≥n Log√≠sitca.

*Finalmente el modelo tiene 49,133 filas y 518 variables pudiendo predecir hasta 16 g√©neros distintos.*

## üß† Tecnolog√≠a y Herramientas
| Categor√≠a | Herramientas Clave |
| :--- | :--- |
| **Modelado & ML** | **TensorFlow/Keras** (Redes Neuronales), **Scikit-learn** (Random Forest, SVM), **Keras Tuner** (Optimizaci√≥n de Hiperpar√°metros). |
| **An√°lisis de Audio** | **Librosa** (Extracci√≥n de MFCCs, ZCR, Tonnetz, etc.) |
| **Lenguaje** | **Python, Streamlit** |
| **Gesti√≥n de Datos** | **Pandas, NumPy** |
| **Visualizaci√≥n** | **Seaborn, Matplotlib** |
| **Ingenier√≠a de ML** | Guardado de **scalers** (`.pkl`) y **modelos**. |

## üìä Exploraci√≥n y Preprocesamiento de Datos (EDA)
El proyecto se bas√≥ en el dataset FMA (Free Music Archive), que contiene metadatos y caracter√≠sticas pre-extra√≠das.

Desaf√≠os Superados:

- **Limpieza de Columnas**: Se manej√≥ la compleja jerarqu√≠a de tres niveles en las columnas de caracter√≠sticas y se convirti√≥ la informaci√≥n de g√©nero de strings a listas.

- **Selecci√≥n del Dataset Ganador**: Se evaluaron 6 combinaciones de datos (Con/Sin Outliers, Crudos/Normalizados/MinMax) para determinar cu√°l ofrec√≠a la mejor Accuracy inicial, encontrando que [Menciona el dataset ganador aqu√≠, ej: X_train_sin_outliers_norm] fue el m√°s efectivo para la clasificaci√≥n.

- **Gesti√≥n del Desequilibrio**: El an√°lisis univariante revel√≥ un marcado desequilibrio de clases (predominio de Electronic, Rock, Experimental), un factor cr√≠tico a considerar en la evaluaci√≥n del rendimiento. Por ello y por falta de datos decidimos mantener los g√©neros musicales m√°s representativos.

- **Gesti√≥n de la RAM**: Para realizar nuestro trabajo nos hemos valido de Google Colab y GitHub Codespaces y pronto nos quedamos sin RAM debido a la gran cantidad de datos que el ordenador deb√≠a procesar. Para ello ajustamos los datatypes y eliminamos todas aquellas variables que dejamos de usar.

## üèÜ Resultados del Modelo
Se compararon cuatro modelos principales. El mejor rendimiento se logr√≥ tras la optimizaci√≥n de hiperpar√°metros de la Red Neuronal mediante Keras Tuner utilizando el mejor dataset seleccionado.

| Modelo | Optimizaci√≥n | Accuracy en Test Set |
| :--- | :--- | :--- |
| **Red Neuronal (DNN)** | Keras Tuner | 68'66% |
| Random Forest | RandomizedSearchCV | % |
| SVM (RBF/Lineal) | RandomizedSearchCV (Subset) | % |
| Regresi√≥n Log√≠stica | Base | % |


ü•á El modelo ganador fue la Red Neuronal con una precisi√≥n final entorno del 68%.

## ‚öôÔ∏è Estructura del Repositorio
```
‚îú‚îÄ‚îÄ music_genre_identifier/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processed/ (Contiene .parquet de X_train/test normalizados/minmaxed)
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ factorized_data/ (Contiene factorized_genre_top.json para decodificaci√≥n)
‚îÇ       ‚îî‚îÄ‚îÄ models/ (Contiene el scaler y los modelos .pkl para despliegue en Streamlit)
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ neural_network.pkl (El objeto del modelo ganador final)
‚îî‚îÄ‚îÄ README.md
```

## üßë‚Äçüíª Co-creadores
Este proyecto fue desarrollado en colaboraci√≥n por:

[Daniel P√°ez](https://github.com/danielpaez-dev) | [Ivan D√≠az](https://github.com/ivandla96) | [Tulio Gim√©nez](https://github.com/TulioGimenez)
